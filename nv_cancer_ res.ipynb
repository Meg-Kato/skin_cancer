{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./HAM10000_metadata.csv\"\n",
    "data_type = {0:'nv', 1:'mel', 2:'bcc'}\n",
    "img_dir = './dataset/img'\n",
    "pre_dir = './ham10000_images'\n",
    "# img_dir1 = './ham10000_images_part_1'\n",
    "# img_dir2 = './ham10000_images_part_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1_bcc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-82d0834267ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_bcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_nv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1_bcc' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(df1_bcc))\n",
    "print(len(df1_mel))\n",
    "print(len(df1_nv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveimg(data_type:dict, img_dir:str, pre_dir:str):\n",
    "    for num in range(3):\n",
    "        df_type = df[df['dx'] == data_type[num]]\n",
    "        filename_type = df_type['image_id'].values\n",
    "        for i in range(len(filename_type)):\n",
    "            image_id_type = filename_type[i]\n",
    "            shutil.copy2(f'{pre_dir}/{image_id_type}.jpg', f'{img_dir}/{data_type[num]}/{data_type[num]}{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "moveimg(data_type, img_dir, pre_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bcc = df[df['dx'] == 'bcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeimg(img_file:str):\n",
    "    img = cv2.imread(img_file)\n",
    "    height = img.shape[0]\n",
    "    width  = img.shape[1]\n",
    "    img2 = cv2.resize(img, (int(width*0.5), int(height*0.50)))\n",
    "    return img2\n",
    "\n",
    "def save_img(data_type:dict, img_dir:str):\n",
    "    for num in range(3):\n",
    "        for i in range(len(df[df['dx'] == data_type[num]])):\n",
    "            img_file = f'{img_dir}/{data_type[num]}/{data_type[num]}{i}.jpg'\n",
    "            new_img = resizeimg(img_file)\n",
    "            cv2.imwrite(f\"{img_dir}/half_size/{data_type[num]}/{data_type[num]}{i}.jpg\", new_img)\n",
    "        \n",
    "def addarray(arr1:list, arr2:list):\n",
    "    if arr1.ndim == 3:\n",
    "        zeroarray = np.zeros((2, arr2.shape[0], arr2.shape[1], 3))\n",
    "        zeroarray[0] += arr1\n",
    "        zeroarray[1] += arr2\n",
    "    else:\n",
    "        zeroarray= np.zeros((arr1.shape[0]+1, arr2.shape[0], arr2.shape[1], 3))\n",
    "        for i in range(arr1.shape[0]):\n",
    "            zeroarray[i] += arr1[i]\n",
    "        zeroarray[zeroarray.shape[0]-1] += arr2\n",
    "    return zeroarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img(data_type, img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒストグラム均一化\n",
    "def equalizeHistRGB(src):\n",
    "\n",
    "    RGB = cv2.split(src)\n",
    "    Blue   = RGB[0]\n",
    "    Green = RGB[1]\n",
    "    Red    = RGB[2]\n",
    "    for i in range(3):\n",
    "        cv2.equalizeHist(RGB[i])\n",
    "\n",
    "    img_hist = cv2.merge([RGB[0],RGB[1], RGB[2]])\n",
    "    return img_hist\n",
    "\n",
    "# ガウシアンノイズ\n",
    "def addGaussianNoise(src):\n",
    "    row,col,ch= src.shape\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = 15\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col,ch)\n",
    "    noisy = src + gauss\n",
    "\n",
    "    return noisy\n",
    "\n",
    "# salt&pepperノイズ\n",
    "def addSaltPepperNoise(src):\n",
    "    row,col,ch = src.shape\n",
    "    s_vs_p = 0.5\n",
    "    amount = 0.004\n",
    "    out = src.copy()\n",
    "    # Salt mode\n",
    "    num_salt = np.ceil(amount * src.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i-1 , int(num_salt))\n",
    "                 for i in src.shape]\n",
    "    out[coords[:-1]] = (255,255,255)\n",
    "\n",
    "    # Pepper mode\n",
    "    num_pepper = np.ceil(amount* src.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i-1 , int(num_pepper))\n",
    "             for i in src.shape]\n",
    "    out[coords[:-1]] = (0,0,0)\n",
    "    return out\n",
    "\n",
    "def numericalSort(value):\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def get_path(data_type:str, img_dir:str):\n",
    "    path = f\"{img_dir}/resize_img/{data_type}/{data_type}*\"\n",
    "    flist = sorted(glob.glob(path), key=numericalSort)\n",
    "    return flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # ルックアップテーブルの生成\n",
    "    min_table = 50\n",
    "    max_table = 205\n",
    "    diff_table = max_table - min_table\n",
    "    gamma1 = 0.75\n",
    "    gamma2 = 1.5\n",
    "\n",
    "    LUT_HC = np.arange(256, dtype = 'uint8' )\n",
    "    LUT_LC = np.arange(256, dtype = 'uint8' )\n",
    "    LUT_G1 = np.arange(256, dtype = 'uint8' )\n",
    "    LUT_G2 = np.arange(256, dtype = 'uint8' )\n",
    "\n",
    "    LUTs = []\n",
    "\n",
    "    # 平滑化用\n",
    "    average_square = (2, 2)\n",
    "\n",
    "    # ハイコントラストLUT作成\n",
    "    for i in range(0, min_table):\n",
    "        LUT_HC[i] = 0\n",
    "\n",
    "    for i in range(min_table, max_table):\n",
    "        LUT_HC[i] = 255 * (i - min_table) / diff_table\n",
    "\n",
    "    for i in range(max_table, 255):\n",
    "        LUT_HC[i] = 255\n",
    "\n",
    "    # その他LUT作成\n",
    "    for i in range(256):\n",
    "        LUT_LC[i] = min_table + i * (diff_table) / 255\n",
    "        LUT_G1[i] = 255 * pow(float(i) / 255, 1.0 / gamma1) \n",
    "        LUT_G2[i] = 255 * pow(float(i) / 255, 1.0 / gamma2)\n",
    "\n",
    "    LUTs.append(LUT_HC)\n",
    "    LUTs.append(LUT_LC)\n",
    "    LUTs.append(LUT_G1)\n",
    "    LUTs.append(LUT_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augumentation(data_type:dict, img_dir:str):\n",
    "    for num in range(3):\n",
    "        j = 1\n",
    "        flist = get_path(data_type[num], img_dir)\n",
    "\n",
    "        for file in flist:\n",
    "            # 画像の読み込み\n",
    "            img_src = cv2.imread(file)\n",
    "            trans_img = []\n",
    "            trans_img.append(img_src)\n",
    "\n",
    "            # LUT変換\n",
    "            for i, LUT in enumerate(LUTs):\n",
    "                trans_img.append(cv2.LUT(img_src, LUT))\n",
    "\n",
    "            # 平滑化      \n",
    "            trans_img.append(cv2.blur(img_src, average_square))      \n",
    "\n",
    "            # ヒストグラム均一化\n",
    "            trans_img.append(equalizeHistRGB(img_src))\n",
    "\n",
    "            # ノイズ付加\n",
    "            trans_img.append(addGaussianNoise(img_src))\n",
    "            trans_img.append(addSaltPepperNoise(img_src))\n",
    "\n",
    "            # 反転\n",
    "            flip_img = []\n",
    "            for img in trans_img:\n",
    "                flip_img.append(cv2.flip(img, 1))\n",
    "            trans_img.extend(flip_img)\n",
    "\n",
    "    #         base = f\"{member}/{member}\"+str(j)+\"_\"\n",
    "            base = f'{img_dir}/aug_img/{data_type[num]}/{data_type[num]}{j}_'\n",
    "            j += 1\n",
    "            img_src.astype(np.float64)\n",
    "            for i, img in enumerate(trans_img):\n",
    "                cv2.imwrite(f'{base}{i}.jpg' ,img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "augumentation(data_type, img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aug_path(data_type:str, img_dir:str):\n",
    "    path = f\"{img_dir}/resize_img/{data_type}/{data_type}*\"\n",
    "    flist = sorted(glob.glob(path), key=numericalSort)\n",
    "    return flist\n",
    "\n",
    "def img_array(data_type:str, img_dir:str, data_num:int):\n",
    "    img_array = np.zeros((data_num, 75, 100))\n",
    "    img_path = get_aug_path(data_type, img_dir)\n",
    "    for i in range(data_num):\n",
    "        img_array[i] += np.array((Image.open(img_path[i])).convert('L'))\n",
    "    img_train, img_test = train_test_split(img_array, train_size= 0.8)\n",
    "    return img_train, img_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepstation/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "nv_train, nv_test = img_array(data_type[0], img_dir, 514)\n",
    "mel_train, mel_test = img_array(data_type[1], img_dir, 514)\n",
    "bcc_train, bcc_test = img_array(data_type[2], img_dir, 514)\n",
    "# bcc_train, bcc_test = img_array(data_type[2], img_dir, 9252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411.20000000000005"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "514*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(dataset:int, data1:list, data2:list, data3:list):\n",
    "#     datasets = {0:7401, 1:1851}\n",
    "    datasets = {0:411, 1:103}\n",
    "    data = {0:data1, 1:data2, 2:data3}\n",
    "    x = np.zeros((datasets[dataset]*3, 75, 100))\n",
    "    for num in range(3):\n",
    "        data_num = data[num]\n",
    "        for i in range(datasets[dataset]):\n",
    "            x[(num*datasets[dataset])+i] += data_num[i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset(0, nv_train, mel_train, bcc_train)\n",
    "x_test = dataset(1, nv_test, mel_test, bcc_test)\n",
    "x_train = x_train.reshape((x_train.shape[0], 75, 100, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 75, 100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.repeat([0, 1, 2], nv_train.shape[0])\n",
    "y_test = np.repeat([0, 1, 2], nv_test.shape[0])\n",
    "# y_train = to_categorical(_y_train)\n",
    "# y_test = to_categorical(_y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = np.mean(x_train)\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_train_std = np.std(x_train)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean)/x_train_std\n",
    "x_test = (x_test - x_test_mean)/x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape\n",
      "x_train: (1109, 75, 100, 1) |-> y_train: (1109, 3),\n",
      "x_test: (309, 75, 100, 1) |-> y_test: (309, 3),\n",
      "x_validate: (124, 75, 100, 1) |-> y_validate: (124, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Dataset shape\n",
    "x_train: {x_train.shape} |-> y_train: {y_train.shape},\n",
    "x_test: {x_test.shape} |-> y_test: {y_test.shape},\n",
    "x_validate: {x_validate.shape} |-> y_validate: {y_validate.shape}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model... /  True 3\n",
      "Train on 1109 samples, validate on 309 samples\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[512,64,75,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_38/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/conv2d_38/convolution_grad/Conv2DBackpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_45/Relu, conv2d_38/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_6/mul/_931}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1745_loss_6/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-0c92fbc0ae3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing model... / \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-0c92fbc0ae3a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, Xtrain, ytrain, Xval, yval, nb_epoch, learning_rate)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;31m# historyの保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[512,64,75,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_38/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/conv2d_38/convolution_grad/Conv2DBackpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_45/Relu, conv2d_38/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_6/mul/_931}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1745_loss_6/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ResNet_build import ResnetBuilder\n",
    "from keras import losses\n",
    "from utility import utility\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.layers import Input, Conv2D, AveragePooling2D, BatchNormalization, Add, Activation, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class TestModel:\n",
    "    def __init__(self, use_resblock, nb_blocks):\n",
    "        self.use_resblock = use_resblock\n",
    "        self.nb_blocks = nb_blocks\n",
    "        # モデルの作成\n",
    "        self.model = self._create_model()\n",
    "        # モデル名\n",
    "        self.name = \"\"\n",
    "        if use_resblock: self.name += \"use_res_\"\n",
    "        else: self.name += \"no_res_\"\n",
    "        self.name = f\"{self.name}{self.nb_blocks:02d}\"\n",
    "\n",
    "    def _create_model(self):\n",
    "        input = Input(shape=(75, 100, 1))\n",
    "        X = input\n",
    "        n_filter = 64\n",
    "        for i in range(self.nb_blocks):\n",
    "            # 3ブロック単位でAveragePoolingを入れる、フィルター数を倍にする\n",
    "            if i % 3 == 0 and i != 0:\n",
    "                X = AveragePooling2D((2,2))(X)\n",
    "                n_filter *= 2\n",
    "            # ショートカットとメインのフィルター数を揃えるために活性化関数なしの畳込みレイヤーを作る\n",
    "            if i % 3 == 0:\n",
    "                X = Conv2D(n_filter, (4,4), padding=\"same\")(X)\n",
    "            # 1ブロック単位の処理\n",
    "            if self.use_resblock:\n",
    "                # ショートカット：ショートカット→BatchNorm（ResBlockを使う場合のみ）\n",
    "                shortcut = X\n",
    "                shortcut = BatchNormalization()(shortcut)\n",
    "            # メイン\n",
    "            # 畳み込み→BatchNorm→活性化関数\n",
    "            X = Conv2D(n_filter, (4,4), padding=\"same\")(X)\n",
    "#             X = BatchNormalization()(X)\n",
    "            X = Activation(\"relu\")(X)\n",
    "            X = Dropout(0.2)(X)\n",
    "            # 畳み込み→BatchNorm\n",
    "#             X = Conv2D(n_filter, (4,4), padding=\"same\")(X)\n",
    "#             X = BatchNormalization()(X)\n",
    "            if self.use_resblock:\n",
    "                # ショートカットとマージ（ResBlockを使う場合のみ）\n",
    "                X = Add()([X, shortcut])\n",
    "            # 活性化関数\n",
    "            X = Activation(\"relu\")(X)\n",
    "        # 全結合\n",
    "        X = Flatten()(X)\n",
    "        y = Dense(3, activation=\"softmax\")(X)\n",
    "        X = Dropout(0.5)(X)\n",
    "        # モデル\n",
    "        model = Model(inputs=input, outputs=y)\n",
    "        return model\n",
    "\n",
    "    def train(self, Xtrain, ytrain, Xval, yval, nb_epoch=70, learning_rate=0.01):\n",
    "        self.model.compile(optimizer=Adam(lr=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        history = self.model.fit(Xtrain, ytrain, batch_size=512, epochs=nb_epoch, validation_data=(Xval, yval)).history\n",
    "        # historyの保存\n",
    "        if not os.path.exists(\"history\"): os.mkdir(\"history\")\n",
    "        self.model.save(f\"./history/{self.name}.h5\")\n",
    "        with open(f\"history/{self.name}.dat\", \"wb\") as fp:\n",
    "            pickle.dump(history, fp)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # データの読み込み\n",
    "    (X_train, y_train), (X_test, y_test) = (x_train, y_train), (x_test, y_test)\n",
    "#     X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "#     y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "    # テストパターン\n",
    "#     resflag = [False, True]\n",
    "    resflag = [True]\n",
    "    nb_blocks = [3, 6, 9, 12]\n",
    "    # モデルの作成\n",
    "    for res in resflag:\n",
    "        for nb in nb_blocks:\n",
    "            print(\"Testing model... / \", res, nb)\n",
    "            model = TestModel(res, nb)\n",
    "            model.train(X_train, y_train, X_test, y_test, nb_epoch=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# データ読み込み\n",
    "no_res, use_res = [], []\n",
    "for i in range(4):\n",
    "    with open(f\"history/no_res_{i*3+3:02d}.dat\", \"rb\") as fp:\n",
    "        no_res.append(pickle.load(fp))\n",
    "    with open(f\"history/use_res_{i*3+3:02d}.dat\", \"rb\") as fp:\n",
    "        use_res.append(pickle.load(fp))\n",
    "\n",
    "xlabels = np.arange(50) + 1\n",
    "cmap = get_cmap(\"Set1\")\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "for i in range(len(no_res)):\n",
    "    plt.plot(xlabels, no_res[i][\"val_acc\"], color=cmap(i), label=\"No_res # blocks=\"+str(i*3+3))\n",
    "plt.legend()\n",
    "plt.ylim((0, 1.0))\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "for i in range(len(no_res)):\n",
    "    plt.plot(xlabels, use_res[i][\"val_acc\"],  color=cmap(i), label=\"Use_res # blocks=\"+str(i*3+3))\n",
    "# plt.legend()\n",
    "plt.ylim((0, 1.0))\n",
    "\n",
    "plt.suptitle(\"Validation accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd38b0c0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# データ読み込み\n",
    "no_res, use_res = [], []\n",
    "for i in range(4):\n",
    "    with open(f\"history/no_res_{i*3+3:02d}.dat\", \"rb\") as fp:\n",
    "        no_res.append(pickle.load(fp))\n",
    "    with open(f\"history/use_res_{i*3+3:02d}.dat\", \"rb\") as fp:\n",
    "        use_res.append(pickle.load(fp))\n",
    "\n",
    "xlabels = np.arange(50) + 1\n",
    "cmap = get_cmap(\"Set1\")\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "for i in range(len(no_res)):\n",
    "    plt.plot(xlabels, no_res[i][\"val_loss\"], color=cmap(i), label=\"No_res # blocks=\"+str(i*3+3))\n",
    "plt.legend()\n",
    "plt.ylim((0, 15.0))\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "for i in range(len(no_res)):\n",
    "    plt.plot(xlabels, use_res[i][\"val_loss\"],  color=cmap(i), label=\"Use_res # blocks=\"+str(i*3+3))\n",
    "# plt.legend()\n",
    "plt.ylim((0, 15.0))\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle(\"Validation loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
